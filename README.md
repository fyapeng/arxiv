# 最新arXiv论文

<!-- ARXIV_PAPERS_START -->
*(Updated on: 2025-08-01 ET)*

1. **[Will Compute Bottlenecks Prevent an Intelligence Explosion?](https://arxiv.org/abs/arXiv:2507.23181)**<br/>计算瓶颈会阻止智能爆炸吗？
    - *Authors: Parker Whitfill, Cheryl Wu*
2. **[Relative Bias Under Imperfect Identification in Observational Causal Inference](https://arxiv.org/abs/arXiv:2507.23743)**<br/>在观察性因果推断中的不完全识别下的相对偏差
    - *Authors: Melody Huang, Cory McCartan*


---

## 文章概览

### 计算瓶颈会阻止智能爆炸吗？
**[Will Compute Bottlenecks Prevent an Intelligence Explosion?](https://arxiv.org/abs/arXiv:2507.23181)**

**Authors**: Parker Whitfill, Cheryl Wu

**Abstract**: The possibility of a rapid, "software-only" intelligence explosion brought on by AI's recursive self-improvement (RSI) is a subject of intense debate within the AI community. This paper presents an economic model and an empirical estimation of the elasticity of substitution between research compute and cognitive labor at frontier AI firms to shed light on the possibility. We construct a novel panel dataset for four leading AI labs (OpenAI, DeepMind, Anthropic, and DeepSeek) from 2014 to 2024 and fit the data to two alternative Constant Elasticity of Substitution (CES) production function models. Our two specifications yield divergent results: a baseline model estimates that compute and labor are substitutes, whereas a 'frontier experiments' model, which accounts for the scale of state-of-the-art models, estimates that they are complements. We conclude by discussing the limitations of our analysis and the implications for forecasting AI progress.

**摘要**: 由人工智能的递归自我改进（RSI）引发的快速、“仅软件”智能爆炸的可能性，在人工智能社区内引发了激烈的辩论。本文提出了一个经济模型和对前沿人工智能公司研究计算与认知劳动之间替代弹性的经验估计，以阐明这种可能性。我们为四家领先的人工智能实验室（OpenAI、DeepMind、Anthropic和DeepSeek）构建了一个从2014年到2024年的新面板数据集，并将数据拟合到两种替代的恒定弹性替代（CES）生产函数模型。我们的两种规范得出了不同的结果：一个基线模型估计计算和劳动力是替代品，而一个“前沿实验”模型，考虑到最先进模型的规模，估计它们是互补品。我们最后讨论了我们分析的局限性和对预测人工智能进展的影响。

---
### 在观察性因果推断中的不完全识别下的相对偏差
**[Relative Bias Under Imperfect Identification in Observational Causal Inference](https://arxiv.org/abs/arXiv:2507.23743)**

**Authors**: Melody Huang, Cory McCartan

**Abstract**: To conduct causal inference in observational settings, researchers must rely on certain identifying assumptions. In practice, these assumptions are unlikely to hold exactly. This paper considers the bias of selection-on-observables, instrumental variables, and proximal inference estimates under violations of their identifying assumptions. We develop bias expressions for IV and proximal inference that show how violations of their respective assumptions are amplified by any unmeasured confounding in the outcome variable. We propose a set of sensitivity tools that quantify the sensitivity of different identification strategies, and an augmented bias contour plot visualizes the relationship between these strategies. We argue that the act of choosing an identification strategy implicitly expresses a belief about the degree of violations that must be present in alternative identification strategies. Even when researchers intend to conduct an IV or proximal analysis, a sensitivity analysis comparing different identification strategies can help to better understand the implications of each set of assumptions. Throughout, we compare the different approaches on a re-analysis of the impact of state surveillance on the incidence of protest in Communist Poland.

**摘要**: 在观察性研究中进行因果推断时，研究者必须依赖某些识别假设。在实践中，这些假设不太可能完全成立。本文考虑了在违反其识别假设的情况下，选择偏差、工具变量和近端推断估计的偏差。我们为工具变量和近端推断开发了偏差表达式，展示了违反各自假设的情况是如何被结果变量中的任何未测量混杂因素放大的。我们提出了一套敏感性工具，用以量化不同识别策略的敏感性，并且增强的偏差轮廓图可视化了这些策略之间的关系。我们认为，选择识别策略的行为隐含地表达了对替代识别策略中必须存在的违规程度的信念。即使研究者打算进行工具变量或近端分析，比较不同识别策略的敏感性分析也有助于更好地理解每组假设的含义。在整个过程中，我们比较了不同方法在重新分析国家监控对共产主义波兰抗议活动发生率影响中的应用。

---
<!-- ARXIV_PAPERS_END -->

---
This page is automatically updated.
